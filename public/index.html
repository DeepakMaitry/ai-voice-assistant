<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Assistant (Continuous)</title>
    <script src="/socket.io/socket.io.js"></script>
    <style>
        body {
            font-family: 'Segoe UI', sans-serif;
            background-color: #f0f2f5;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
        }
        #status {
            font-size: 1.5rem;
            margin-bottom: 20px;
            color: #555;
            font-weight: bold;
            height: 30px;
        }
        .controls {
            display: flex;
            gap: 20px;
        }
        button {
            border: none;
            padding: 15px 30px;
            font-size: 1.2rem;
            border-radius: 50px;
            cursor: pointer;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            transition: all 0.3s;
        }
        #startBtn {
            background-color: #4285F4;
            color: white;
        }
        #startBtn:hover { background-color: #357ae8; }
        
        #stopBtn {
            background-color: #EA4335;
            color: white;
            display: none; /* Hidden at first */
        }
        #stopBtn:hover { background-color: #c5221f; }

        .listening {
            box-shadow: 0 0 15px rgba(66, 133, 244, 0.5);
            transform: scale(1.05);
        }

        #transcript {
            margin-top: 30px;
            padding: 20px;
            background: white;
            border-radius: 10px;
            width: 80%;
            max-width: 600px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.05);
            min-height: 100px;
            max-height: 300px;
            overflow-y: auto;
        }
        p { margin: 10px 0; }
    </style>
</head>
<body>

    <div id="status">Ready to Talk</div>
    
    <div class="controls">
        <button id="startBtn">Start Conversation</button>
        <button id="stopBtn">Stop</button>
    </div>

    <div id="transcript"></div>

    <script>
        const socket = io();
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const status = document.getElementById('status');
        const transcript = document.getElementById('transcript');

        let recognition;
        let audioQueue = [];
        let isPlaying = false;
        let isConversationActive = false; // Controls the loop

        // 1. Setup Ears (Speech Recognition)
        if ('webkitSpeechRecognition' in window) {
            recognition = new webkitSpeechRecognition();
            recognition.continuous = false; // We restart it manually
            recognition.lang = 'en-US';

            recognition.onstart = () => {
                status.innerText = "Listening... ðŸ‘‚";
                startBtn.classList.add('listening');
            };

            recognition.onend = () => {
                startBtn.classList.remove('listening');
                // Note: We do NOT restart here yet. We wait for AI to finish speaking.
            };

            recognition.onresult = (event) => {
                const text = event.results[0][0].transcript;
                status.innerText = "Thinking... ðŸ§ ";
                transcript.innerHTML += `<p><strong>You:</strong> ${text}</p>`;
                
                // Send to Brain
                socket.emit('user_message', { message: text });
            };
        } else {
            alert("Please use Google Chrome for this.");
        }

        // 2. Button Logic
        startBtn.onclick = () => {
            isConversationActive = true;
            startBtn.style.display = 'none';
            stopBtn.style.display = 'block';
            recognition.start();
        };

        stopBtn.onclick = () => {
            isConversationActive = false;
            startBtn.style.display = 'block';
            stopBtn.style.display = 'none';
            status.innerText = "Conversation Ended.";
            recognition.stop();
        };

        // 3. Handle Incoming Voice (The Loop)
        socket.on('ai_audio_chunk', (data) => {
            // Display text
            if (!document.getElementById('current-ai-text')) {
                transcript.innerHTML += `<p><strong>AI:</strong> <span id="current-ai-text"></span></p>`;
            }
            document.getElementById('current-ai-text').innerText += " " + data.text;

            // Play Audio
            audioQueue.push(data.audio);
            playNextChunk();
        });

        socket.on('ai_response_complete', () => {
            // Remove the ID so next response starts a new line
            const oldText = document.getElementById('current-ai-text');
            if (oldText) oldText.removeAttribute('id');
        });

        function playNextChunk() {
            if (isPlaying || audioQueue.length === 0) {
                // If queue is empty AND we are not playing AND conversation is active...
                if (!isPlaying && audioQueue.length === 0 && isConversationActive) {
                    // ...Restart the Mic! (The Loop)
                    status.innerText = "My turn finished. Listening again...";
                    try { recognition.start(); } catch(e) {}
                }
                return;
            }

            isPlaying = true;
            status.innerText = "Speaking... ðŸ—£ï¸";
            
            const audioData = audioQueue.shift();
            const audio = new Audio("data:audio/mp3;base64," + audioData);

            audio.onended = () => {
                isPlaying = false;
                // Recursive call to play next chunk OR restart mic
                playNextChunk(); 
            };

            audio.play();
        }
    </script>
</body>
</html>